services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: hw1-api
    environment:
      ASPNETCORE_ENVIRONMENT: ${ASPNETCORE_ENVIRONMENT}
      ASPNETCORE_URLS: http://+:8080
      DOTNET_RUNNING_IN_CONTAINER: "true"
      ConnectionStrings__PostgresConnection: "Host=postgres;Port=5432;Database=${POSTGRES_DB};Username=${POSTGRES_USER};Password=${POSTGRES_PASSWORD};"
      ConnectionStrings__RedisConnection: redis:6379
      TelegramBot__BotToken: ${TELEGRAM_BOT_TOKEN}
      OpenSearch__Url: "http://opensearch-node1:9200"
    #  OpenSearch__User: "admin"
    #  OpenSearch__Password: "${OPENSEARCH_INITIAL_ADMIN_PASSWORD}"
      OpenSearch__DisableSslVerification: "true"
      
      # Kafka настройки
      Kafka__BootstrapServers: kafka:19092
      Kafka__ConsumerGroup: telegram-bot
      Kafka__Topics__UserEvents: telegram.user.events
      Kafka__Topics__CommandEvents: telegram.command.events
      Kafka__Topics__RegistrationEvents: telegram.registration.events
      Kafka__Topics__ErrorEvents: telegram.error.events
      Kafka__Topics__AnalyticsAlerts: telegram.analytics.alerts
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./logs:/app/Logs
    networks:
      - backend
      - opensearch-net
      - kafka-net
    restart: unless-stopped

  postgres:
    image: postgres:17-alpine
    container_name: hw1-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    
  redis:
    image: redis:8.2.2-alpine
    container_name: hw1-redis
    command: redis-server --appendonly yes --loglevel warning
    volumes:
      - redis_data:/data
    networks:
      - backend
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: unless-stopped

  nginx:
    image: nginx:1.29-alpine
    container_name: hw1-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
    depends_on:
      - api
    networks:
      - backend
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped
    
  opensearch-node1:
    image: opensearchproject/opensearch:3
    container_name: opensearch-node-1
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node1 # имя ноды, которая запускается в этом контейнере
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 # список узлов, к которым будет пытаться подключится текущий узел для образования кластера
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 # ноды, на основе которых будет выбираться мастер нода в созданном кластере
      - bootstrap.memory_lock=true # запрещает ОС выгружать память JVM процесса на swap память на диске
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" # определение минимального и максимального размера кучиJVM
  #   - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
      - "DISABLE_SECURITY_PLUGIN=true" 
    ulimits: # ограничения ОС, которые может использовать процесс 
      memlock:
        soft: -1 # разрешает неограниченную блокировку памяти. Мягкое разрешение, которое можно временно привысить. (нужно при включенном bootstrap.memory_lock=true)
        hard: -1 # максимальный лимит тоже не ограничен
      nofile:
        soft: 65536 # один процесс может открыть до 65536 файлов одновременно
        hard: 65536
    volumes:
      - opensearch-data1:/usr/share/opensearch/data
    ports:
      - "9200:9200" # REST API
      - "9600:9600" # Анализатор производительности
    networks:
      - opensearch-net
    healthcheck:
      test: [ "CMD-SHELL", "curl -s -f http://localhost:9200/_cluster/health > /dev/null || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    
  opensearch-node2:
    image: opensearchproject/opensearch:3
    container_name: opensearch-node-2
    environment:
      - cluster.name=opensearch-cluster
      - node.name=opensearch-node2
      - discovery.seed_hosts=opensearch-node1,opensearch-node2 
      - cluster.initial_cluster_manager_nodes=opensearch-node1,opensearch-node2 
      - bootstrap.memory_lock=true 
      - "OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m" 
  #   - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${OPENSEARCH_INITIAL_ADMIN_PASSWORD}
      - "DISABLE_INSTALL_DEMO_CONFIG=true"
      - "DISABLE_SECURITY_PLUGIN=true"
    ulimits:  
      memlock:
        soft: -1 
        hard: -1 
      nofile:
        soft: 65536 
        hard: 65536
    volumes:
      - opensearch-data2:/usr/share/opensearch/data
    networks:
      - opensearch-net  
    healthcheck:
      test: [ "CMD-SHELL", "curl -s -f http://localhost:9200/_cluster/health > /dev/null || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:3
    container_name: opensearch-dashboards
    ports:
      - 5601:5601
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch-node1:9200","http://opensearch-node2:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: true
    networks:
      - opensearch-net
    depends_on:
      opensearch-node1:
        condition: service_healthy
      opensearch-node2:
        condition: service_healthy
    
  zookeeper:
    image: confluentinc/cp-zookeeper:7.8.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_SERVERS: zookeeper:2888:3888    
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      kafka-net:
    
  kafka:
    image: confluentinc/cp-kafka:7.8.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:19092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_LOG_RETENTION_HOURS: 168  # 7 дней
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "kafka-topics", "--bootstrap-server", "localhost:19092", "--list" ]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      kafka-net:
      
  kafka-ui:
    image: provectuslabs/kafka-ui:v0.7.2
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8082:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:19092
      DYNAMIC_CONFIG_ENABLED: "true"
    networks:
      kafka-net:
    
volumes:
  postgres_data:
  redis_data:
  opensearch-data1:
  opensearch-data2:

networks:
  backend:
    driver: bridge
  opensearch-net:
    driver: bridge
  kafka-net:
    driver: bridge